{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-11T01:30:30.331726Z","iopub.execute_input":"2022-01-11T01:30:30.332465Z","iopub.status.idle":"2022-01-11T01:30:30.359225Z","shell.execute_reply.started":"2022-01-11T01:30:30.332362Z","shell.execute_reply":"2022-01-11T01:30:30.358558Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Conv2D 적용하기\n* Conv2D() 를 모델에 적용 시에는 반드시 입력은 배치 크기를 제외하고 3차원이 되어야 함(즉 배치를 포함하면 4차원)  ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\nfrom tensorflow.keras.models import Model\n\ninput_tensor = Input(shape=(28, 28, 1)) # Conv2D는 배치를 제외하고 3차원 입력해야 됨, tf는 채널이 마지막으로 감 \n# rgb 파일을 다룰시 채널은 3이 들어가야함 \nx = Conv2D(filters=4, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\n# x가 피쳐맵\nprint('x type:', type(x), 'x:', x)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:30:30.360837Z","iopub.execute_input":"2022-01-11T01:30:30.361150Z","iopub.status.idle":"2022-01-11T01:30:37.562654Z","shell.execute_reply.started":"2022-01-11T01:30:30.361112Z","shell.execute_reply":"2022-01-11T01:30:37.561960Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Pooling 적용하기","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tensor = Input(shape=(28, 28, 1))\nx = Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\nx = MaxPooling2D(2)(x)\nprint(x)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:30:37.564130Z","iopub.execute_input":"2022-01-11T01:30:37.564601Z","iopub.status.idle":"2022-01-11T01:30:37.583164Z","shell.execute_reply.started":"2022-01-11T01:30:37.564563Z","shell.execute_reply":"2022-01-11T01:30:37.582346Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### CNN 모델 생성","metadata":{}},{"cell_type":"code","source":"input_tensor = Input(shape=(28, 28, 1))\nx = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\nx = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\nx = MaxPooling2D(2)(x)\n\nmodel = Model(inputs=input_tensor, outputs=x)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:30:37.585535Z","iopub.execute_input":"2022-01-11T01:30:37.585830Z","iopub.status.idle":"2022-01-11T01:30:37.625940Z","shell.execute_reply.started":"2022-01-11T01:30:37.585792Z","shell.execute_reply":"2022-01-11T01:30:37.625184Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten\n\ninput_tensor = Input(shape=(28, 28, 1))\nx = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\nx = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\nx = MaxPooling2D(2)(x)\n\n# 3차원으로 되어있는 Feature map 결과를 Fully Connected 연결하기 위해서는 Flatten()을 적용해야함. \nx = Flatten()(x)\nx = Dense(100, activation='relu')(x)\noutput = Dense(10, activation='softmax')(x)\nmodel = Model(inputs=input_tensor, outputs=output)\nmodel.summary()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:30:37.627369Z","iopub.execute_input":"2022-01-11T01:30:37.627877Z","iopub.status.idle":"2022-01-11T01:30:37.673664Z","shell.execute_reply.started":"2022-01-11T01:30:37.627841Z","shell.execute_reply":"2022-01-11T01:30:37.672956Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Fashion MNIST 데이터 전처리후 모델 학습","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.datasets import fashion_mnist\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n# 전체 6만개 데이터 중, 5만개는 학습 데이터용, 1만개는 테스트 데이터용으로 분리\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\ndef get_preprocessed_data(images, labels):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    images = np.array(images/255.0, dtype=np.float32)\n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\n# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \ndef get_preprocessed_ohe(images, labels):\n    images, labels = get_preprocessed_data(images, labels)\n    # OHE 적용 \n    oh_labels = to_categorical(labels)\n    return images, oh_labels\n\n# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \ndef get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n    \n    # 학습 데이터를 검증 데이터 세트로 다시 분리\n    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n    \n    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n\n\n# Fashion MNIST 데이터 재 로딩 및 전처리 적용하여 학습/검증/데이터 세트 생성. \n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\nprint(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\nprint(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:30:37.674886Z","iopub.execute_input":"2022-01-11T01:30:37.675395Z","iopub.status.idle":"2022-01-11T01:30:39.836878Z","shell.execute_reply.started":"2022-01-11T01:30:37.675359Z","shell.execute_reply":"2022-01-11T01:30:39.836091Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.metrics import Accuracy\n\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:30:39.838144Z","iopub.execute_input":"2022-01-11T01:30:39.838716Z","iopub.status.idle":"2022-01-11T01:30:39.855684Z","shell.execute_reply.started":"2022-01-11T01:30:39.838673Z","shell.execute_reply":"2022-01-11T01:30:39.854893Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels))","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:30:39.857069Z","iopub.execute_input":"2022-01-11T01:30:39.857324Z","iopub.status.idle":"2022-01-11T01:31:56.864606Z","shell.execute_reply.started":"2022-01-11T01:30:39.857273Z","shell.execute_reply":"2022-01-11T01:31:56.863844Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### 모델 성능 평가","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_history(history):\n    plt.plot(history.history['accuracy'], label='train')\n    plt.plot(history.history['val_accuracy'], label='valid')\n    plt.legend()\n    \nshow_history(history)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:31:56.865951Z","iopub.execute_input":"2022-01-11T01:31:56.866205Z","iopub.status.idle":"2022-01-11T01:31:57.116045Z","shell.execute_reply.started":"2022-01-11T01:31:56.866169Z","shell.execute_reply":"2022-01-11T01:31:57.115400Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# 테스트 데이터 세트로 모델 성능 검증\nmodel.evaluate(test_images, test_oh_labels, batch_size=256, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:31:57.118997Z","iopub.execute_input":"2022-01-11T01:31:57.119518Z","iopub.status.idle":"2022-01-11T01:31:57.435990Z","shell.execute_reply.started":"2022-01-11T01:31:57.119486Z","shell.execute_reply":"2022-01-11T01:31:57.435333Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Dropout을 적용하여 Fully Connected Layer의 오버피팅 조정\n* CNN은 일반적으로 Dense Layer보다는 파라미터수(weight 수) 작음\n* 하지만 많은 Filter 들을 적용하고 이를  Fully Connected Layer로 연결 시 파라미터 수가 늘어남. \n* Flatten() 이후 Dropout을 적용하여 특정 비율로 FC Layer 연결을 누락 적용. ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten, Dropout\n\ninput_tensor = Input(shape=(28, 28, 1))\nx = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\nx = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\nx = MaxPooling2D(2)(x)\n\nx = Flatten()(x)\nx = Dropout(rate=0.5)(x)\nx = Dense(100, activation='relu')(x)\noutput = Dense(10, activation='softmax')(x)\nmodel = Model(inputs=input_tensor, outputs=output)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:31:57.437413Z","iopub.execute_input":"2022-01-11T01:31:57.437667Z","iopub.status.idle":"2022-01-11T01:31:57.488770Z","shell.execute_reply.started":"2022-01-11T01:31:57.437633Z","shell.execute_reply":"2022-01-11T01:31:57.487737Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels))","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:31:57.490037Z","iopub.execute_input":"2022-01-11T01:31:57.490282Z","iopub.status.idle":"2022-01-11T01:33:10.748938Z","shell.execute_reply.started":"2022-01-11T01:31:57.490251Z","shell.execute_reply":"2022-01-11T01:33:10.748251Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"show_history(history)\nmodel.evaluate(test_images, test_oh_labels, batch_size=256, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:33:10.751782Z","iopub.execute_input":"2022-01-11T01:33:10.751988Z","iopub.status.idle":"2022-01-11T01:33:11.221208Z","shell.execute_reply.started":"2022-01-11T01:33:10.751961Z","shell.execute_reply":"2022-01-11T01:33:11.219477Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n\ndef create_model():\n    input_tensor = Input(shape=(28, 28, 1))\n    x = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)\n    x = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\n    x = MaxPooling2D(2)(x)\n\n    #x = Dropout(rate=0.5)(x)\n    x = Flatten()(x)\n    x = Dropout(rate=0.5)(x)\n    x = Dense(200, activation='relu')(x)\n    X = Dropout(rate=0.2)(x)\n    output = Dense(10, activation='softmax')(x)\n    model = Model(inputs=input_tensor, outputs=output)\n    model.summary()\n    \n    return model\n\nmodel = create_model()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:33:11.222381Z","iopub.execute_input":"2022-01-11T01:33:11.222645Z","iopub.status.idle":"2022-01-11T01:33:11.474667Z","shell.execute_reply.started":"2022-01-11T01:33:11.222608Z","shell.execute_reply":"2022-01-11T01:33:11.473953Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels))","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:33:11.475948Z","iopub.execute_input":"2022-01-11T01:33:11.476189Z","iopub.status.idle":"2022-01-11T01:34:29.582658Z","shell.execute_reply.started":"2022-01-11T01:33:11.476154Z","shell.execute_reply":"2022-01-11T01:34:29.581955Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"show_history(history)\nmodel.evaluate(test_images, test_oh_labels, batch_size=256, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:34:29.584015Z","iopub.execute_input":"2022-01-11T01:34:29.585478Z","iopub.status.idle":"2022-01-11T01:34:30.033756Z","shell.execute_reply.started":"2022-01-11T01:34:29.585445Z","shell.execute_reply":"2022-01-11T01:34:30.033086Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### 입력 이미지는 배치를 포함하여 4차원이 되어야 함(즉 배치를 제외하면 3차원)\n* Conv2D()는 입력으로 배치를 제외하고 3차원 입력이 되어야 함. \n* 하지만 2차원으로 입력해도 Input(shape=(28, 28, 1)) 에서 3차원으로 변경함. \n* 명확하게는 2차원 Grayscale이미지더라도 입력 numpy 이미지 배열에서 배치를 제외한 3차원 입력을 만들어 주는게 좋음. ","metadata":{}},{"cell_type":"code","source":"(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\nprint('before reshape:', train_images.shape, test_images.shape)\ntrain_images = np.reshape(train_images, (60000, 28, 28, 1))\ntest_images = np.reshape(test_images, (10000, 28, 28, 1))\nprint('after reshape:', train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n\n(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\nprint(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:34:30.034916Z","iopub.execute_input":"2022-01-11T01:34:30.035153Z","iopub.status.idle":"2022-01-11T01:34:30.720811Z","shell.execute_reply.started":"2022-01-11T01:34:30.035118Z","shell.execute_reply":"2022-01-11T01:34:30.720069Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\nmodel = create_model()\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels))","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:34:30.722088Z","iopub.execute_input":"2022-01-11T01:34:30.722512Z","iopub.status.idle":"2022-01-11T01:35:49.286383Z","shell.execute_reply.started":"2022-01-11T01:34:30.722474Z","shell.execute_reply":"2022-01-11T01:35:49.285685Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"show_history(history)\nmodel.evaluate(test_images, test_oh_labels, batch_size=256, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:35:49.287817Z","iopub.execute_input":"2022-01-11T01:35:49.288063Z","iopub.status.idle":"2022-01-11T01:35:49.886773Z","shell.execute_reply.started":"2022-01-11T01:35:49.288029Z","shell.execute_reply":"2022-01-11T01:35:49.886100Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stride가 1이고 Padding이 없는 경우\n* I는 입력 Feature Map의 크기, F는 Filter의 크기(Kernel size), P는 Padding(정수), S는 Strides(정수)\n* O = (I - F + 2P)/2 + 1 = (5 - 3 + 0 )/1 + 1 = 3","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\nfrom tensorflow.keras.models import Model\n\ninput_tensor = Input(shape=(5, 5, 1))\nx = Conv2D(filters=1, kernel_size=3, strides=1)(input_tensor)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:35:49.888025Z","iopub.execute_input":"2022-01-11T01:35:49.889647Z","iopub.status.idle":"2022-01-11T01:35:49.906870Z","shell.execute_reply.started":"2022-01-11T01:35:49.889617Z","shell.execute_reply":"2022-01-11T01:35:49.906209Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Stride가 1이고 Padding이 1인 경우\n* O = (I - F + 2P)/2 + 1 = (5 - 3 + 2 )/1 + 1 = 5","metadata":{}},{"cell_type":"code","source":"input_tensor = Input(shape=(5, 5, 1))\nx = Conv2D(filters=1, kernel_size=3, strides=1, padding='same')(input_tensor)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:35:49.908060Z","iopub.execute_input":"2022-01-11T01:35:49.908317Z","iopub.status.idle":"2022-01-11T01:35:49.923510Z","shell.execute_reply.started":"2022-01-11T01:35:49.908270Z","shell.execute_reply":"2022-01-11T01:35:49.922712Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# ZeroPadding2D Layer를 이용하여 padding을 수동으로 적용. \nfrom tensorflow.keras.layers import ZeroPadding2D\n\ninput_tensor = Input(shape=(5, 5, 1))\npadded_input = ZeroPadding2D(padding=1)(input_tensor)\nprint('shape after padding:', padded_input.shape)\nx = Conv2D(filters=1, kernel_size=3, strides=1)(padded_input)\nprint('x.shape:', x.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:35:49.924957Z","iopub.execute_input":"2022-01-11T01:35:49.925230Z","iopub.status.idle":"2022-01-11T01:35:49.943254Z","shell.execute_reply.started":"2022-01-11T01:35:49.925187Z","shell.execute_reply":"2022-01-11T01:35:49.942438Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Stride가 2이고 Padding이 없는 경우 \n* O = (I - F + 2P)/2 + 1 = (5 - 3)/2 + 1 = 2","metadata":{}},{"cell_type":"code","source":"input_tensor = Input(shape=(5, 5, 1))\nx = Conv2D(filters=1, kernel_size=3, strides=2)(input_tensor)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:35:49.944708Z","iopub.execute_input":"2022-01-11T01:35:49.944959Z","iopub.status.idle":"2022-01-11T01:35:49.959274Z","shell.execute_reply.started":"2022-01-11T01:35:49.944925Z","shell.execute_reply":"2022-01-11T01:35:49.958570Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Stride가 2이고 Padding은 1 적용\n* O = (I - F + 2P)/2 + 1 = (5 - 3 + 2)/2 + 1 = 3","metadata":{}},{"cell_type":"code","source":"input_tensor = Input(shape=(5, 5, 1))\npadded_input = ZeroPadding2D(padding=1)(input_tensor)\nprint('shape after padding:', padded_input.shape)\nx = Conv2D(filters=1, kernel_size=3, strides=2)(padded_input)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:35:49.960576Z","iopub.execute_input":"2022-01-11T01:35:49.960820Z","iopub.status.idle":"2022-01-11T01:35:49.979399Z","shell.execute_reply.started":"2022-01-11T01:35:49.960788Z","shell.execute_reply":"2022-01-11T01:35:49.978591Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### 입력이 6X6에서 Stride가 2 적용\n* O = (I - F + 2P)/2 + 1 = (6 - 3 + 0)/2 + 1 = 2.5 = 2","metadata":{}},{"cell_type":"code","source":"input_tensor = Input(shape=(6, 6, 1))\nx = Conv2D(filters=1, kernel_size=3, strides=2)(input_tensor)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:35:49.980753Z","iopub.execute_input":"2022-01-11T01:35:49.980999Z","iopub.status.idle":"2022-01-11T01:35:49.995659Z","shell.execute_reply.started":"2022-01-11T01:35:49.980966Z","shell.execute_reply":"2022-01-11T01:35:49.995013Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"input_tensor = Input(shape=(6, 6, 1))\nx = Conv2D(filters=1, kernel_size=3, strides=2, padding='same')(input_tensor)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:35:49.996556Z","iopub.execute_input":"2022-01-11T01:35:49.996731Z","iopub.status.idle":"2022-01-11T01:35:50.012383Z","shell.execute_reply.started":"2022-01-11T01:35:49.996708Z","shell.execute_reply":"2022-01-11T01:35:50.011508Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"input_tensor = Input(shape=(6, 6, 1))\npadded_input = ZeroPadding2D(padding=1)(input_tensor)\nx = Conv2D(filters=1, kernel_size=3, strides=2, padding='valid')(padded_input)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:35:50.013741Z","iopub.execute_input":"2022-01-11T01:35:50.014065Z","iopub.status.idle":"2022-01-11T01:35:50.032037Z","shell.execute_reply.started":"2022-01-11T01:35:50.014028Z","shell.execute_reply":"2022-01-11T01:35:50.031220Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"input_tensor = Input(shape=(6, 6, 1))\npadded_input = ZeroPadding2D(padding=((1, 0),(1,0)))(input_tensor)\nx = Conv2D(filters=1, kernel_size=3, strides=2)(padded_input)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:35:50.036037Z","iopub.execute_input":"2022-01-11T01:35:50.037633Z","iopub.status.idle":"2022-01-11T01:35:50.054134Z","shell.execute_reply.started":"2022-01-11T01:35:50.037607Z","shell.execute_reply":"2022-01-11T01:35:50.053354Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### Maxpooling 적용","metadata":{}},{"cell_type":"code","source":"input_tensor = Input(shape=(223, 223, 1))\nx = MaxPooling2D(2)(input_tensor)\nprint('x.shape:', x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T01:35:50.055374Z","iopub.execute_input":"2022-01-11T01:35:50.055672Z","iopub.status.idle":"2022-01-11T01:35:50.067709Z","shell.execute_reply.started":"2022-01-11T01:35:50.055636Z","shell.execute_reply":"2022-01-11T01:35:50.066885Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}